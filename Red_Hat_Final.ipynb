{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Preprocessing/Merging People and Activities\n\nThis script converts features in people and activities into integers, then merges everything into a single table. Makes it easy to drop into classifiers in Sklearn or XGBoost. \n\nConveniently, most of the data can be easily encoded to numeric values with simple string splitting. \n\nScored ~0.944 with Random Forest Classifier in Sklearn out of the box. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\n\nact_train = pd.read_csv('../input/act_train.csv')\nact_test = pd.read_csv('../input/act_test.csv')\npeople = pd.read_csv('../input/people.csv')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Save the test IDs for Kaggle submission\ntest_ids = act_test['activity_id']\n\ndef preprocess_acts(data, train_set=True):\n    \n    # Getting rid of data feature for now\n    data = data.drop(['date', 'activity_id'], axis=1)\n    if(train_set):\n        data = data.drop(['outcome'], axis=1)\n    \n    ## Split off _ from people_id\n    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    columns = list(data.columns)\n    \n    # Convert strings to ints\n    for col in columns[1:]:\n        data[col] = data[col].fillna('type 0')\n        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n        data[col] = pd.to_numeric(data[col]).astype(int)\n    return data\n\ndef preprocess_people(data):\n    \n    # TODO refactor this duplication\n    data = data.drop(['date'], axis=1)\n    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    #  Values in the people df is Booleans and Strings    \n    columns = list(data.columns)\n    bools = columns[11:]\n    strings = columns[1:11]\n    \n    for col in bools:\n        data[col] = pd.to_numeric(data[col]).astype(int)        \n    for col in strings:\n        data[col] = data[col].fillna('type 0')\n        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n        data[col] = pd.to_numeric(data[col]).astype(int)\n    return data",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Preprocess each df\npeeps = preprocess_people(people)\nactions_train = preprocess_acts(act_train)\nactions_test = preprocess_acts(act_test, train_set=False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "features = actions_train.merge(peeps, how='left', on='people_id')\nlabels = act_train['outcome']\ntest = actions_test.merge(peeps, how='left', on='people_id')\nfeatures.sample(10)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## Split Training Data\nfrom sklearn.cross_validation import train_test_split\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=num_test, random_state=23)\n\n## Out of box random forest\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.grid_search import GridSearchCV\n\nclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n                                 max_depth=1, random_state=0).fit(X_train, y_train)\nclf.score(X_test, y_test) ",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## Training Predictions\nproba = clf.predict_proba(X_test)\npreds = proba[:,1]\nscore = roc_auc_score(y_test, preds)\nprint(\"Area under ROC {0}\".format(score))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Test Set Predictions\ntest_proba = clf.predict_proba(test)\ntest_preds = test_proba[:,1]\n\n# Format for submission\noutput = pd.DataFrame({ 'activity_id' : test_ids, 'outcome': test_preds })\noutput.head()\noutput.to_csv('gauty.csv', index = False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}